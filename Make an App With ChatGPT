https://www.youtube.com/watch?v=5UYgJ4RFEBI

How To Make an App With ChatGPT (Without Knowing Code)

Capture a Scribe
Capture a browser.

for example capture a amazion.com
create a amazion itmes pictures at bowser.


At ChatGPT type: can you make a python script that captures a screenshot every time a click my mouse?

ChatGPT: Yes! Here's a Python script that captures a screenshot every time you click your mouse, using the pynput and Pillow libraries:

ðŸ”§ Requirements
Install these Python packages if you haven't already:
go to VSCode\View\Terminal to run
pip install pynput pillow

Create pyhon codes:

from pynput import mouse
from PIL import ImageGrab
import os
import time

# Directory to save screenshots
output_dir = "screenshots"
os.makedirs(output_dir, exist_ok=True)

def on_click(x, y, button, pressed):
    if pressed:
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = os.path.join(output_dir, f"screenshot_{timestamp}.png")
        screenshot = ImageGrab.grab()
        screenshot.save(filename)
        print(f"Screenshot saved to {filename}")

# Start listening for mouse clicks
with mouse.Listener(on_click=on_click) as listener:
    print("Listening for mouse clicks... Press Ctrl+C to stop.")
    listener.join()

Opwen VSCode and copy code to VSCode and create a new python codes.

PS C:\Users\hwang\Documents> python C:\Users\hwang\OneDrive\Documents\chatGPTtoPythonApp.py
click mouse and creted screenshots.png files at 
C:\Users\hwang\Documents\screenshots


#########################################
python_book analysis
Read pdf file and analyis text data.

open file C:\Workarea\python_book analysis\Read_pdf.py at VSCodes.
RUnning debug of Read_pdf.py file.

first install pip
then 
C:\Workarea\python_book analysis>pip install pydef --user
C:\Workarea\python_book analysis>pip install pdfplumber --user
C:\Workarea\python_book analysis>pip install transformers --user
C:\Workarea\python_book analysis>pip install pandas --user

Running Read_pdf.py

import pypdf
import pdfplumber
from transformers import pipeline
import pandas as pd

def extract_paragraphs_from_pdf(file_path):
    paragraphs = []
    with pdfplumber.open(file_path) as pdf:
        for page in pdf.pages:
            text = page.extract_text()
            if text:
                for line in text.split('\n'):
                    if line.strip():
                        paragraphs.append(line.strip())
    return paragraphs

def split_long_paragraphs(paragraphs, max_length=300):
    res = []
    for p in paragraphs:
        if len(p) <= max_length:
            res.append(p)
        else:
            buf = ""
            for sent in p.split('ã€‚'):
                if len(buf) + len(sent) < max_length:
                    buf += sent + "ã€‚"
                else:
                    res.append(buf)
                    buf = sent + "ã€‚"
            if buf:
                res.append(buf)
    return res

def classify_paragraphs(paragraphs, labels):
    # Ensure the classifier is initialized
    if 'classifier' not in globals():
        global classifier
        classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli")

    out = []
    for i, p in enumerate(paragraphs):
        res = classifier(p, candidate_labels=labels)
        out.append({"æ®µè½ç¼–å·": i+1, "åˆ†ç±»æ ‡ç­¾": res['labels'][0], "åŽŸæ–‡å†…å®¹": p})
        if (i+1)%20 == 0:
            print(f"å·²åˆ†ç±» {i+1}/{len(paragraphs)} æ®µ...")
    return out

def save_to_excel(data, path):
    pd.DataFrame(data).to_excel(path, index=False)
    print("å·²ä¿å­˜ Excelï¼š", path)

# Define labels here
labels = ["äº‹å®ž", "è®®è®º", "æŠ’æƒ…", "é€»è¾‘æŽ¨ç†", "ç»“è®º"]


if __name__ == "__main__":
    paras = extract_paragraphs_from_pdf("Bridge Launching (Marco Rosignoli)(readable).pdf")
    print(paras)

    split_paras = split_long_paragraphs(paras)
    print(f"æ€»æ®µè½æ•°ï¼ˆæ‹†åˆ†åŽï¼‰ï¼š{len(split_paras)}")

    # Add the code from cell q3XVaC6A8mvx here
    print("åŽŸå§‹æ®µè½æ•°é‡ï¼š", len(paras))
    print("æ‹†åˆ†åŽæ®µè½æ•°é‡ï¼š", len(split_paras))

    # åªçœ‹å‰ 2 æ®µæ˜¯å¦æ­£å¸¸
    for i, p in enumerate(split_paras[:2]):
        print(f"æ®µè½ {i+1}ï¼š{p[:60]}...")


    # åªå¤„ç†å‰50æ®µä»¥ä¾¿æµ‹è¯•ï¼Œå¯æ ¹æ®éœ€è¦å¢žåŠ 
    results = classify_paragraphs(split_paras[:50], labels)

    if results:
        excel_path = "bridge_summary.xlsx"
        save_to_excel(results, excel_path)
    else:
        print("æ²¡æœ‰ç”Ÿæˆåˆ†ç±»ç»“æžœï¼Œè·³è¿‡ä¿å­˜Excelå’ŒWordæŠ¥å‘Šã€‚")



