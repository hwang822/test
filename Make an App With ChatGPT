https://www.youtube.com/watch?v=5UYgJ4RFEBI

How To Make an App With ChatGPT (Without Knowing Code)

Capture a Scribe
Capture a browser.

for example capture a amazion.com
create a amazion itmes pictures at bowser.


At ChatGPT type: can you make a python script that captures a screenshot every time a click my mouse?

ChatGPT: Yes! Here's a Python script that captures a screenshot every time you click your mouse, using the pynput and Pillow libraries:

🔧 Requirements
Install these Python packages if you haven't already:
go to VSCode\View\Terminal to run
pip install pynput pillow

Create pyhon codes:

from pynput import mouse
from PIL import ImageGrab
import os
import time

# Directory to save screenshots
output_dir = "screenshots"
os.makedirs(output_dir, exist_ok=True)

def on_click(x, y, button, pressed):
    if pressed:
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = os.path.join(output_dir, f"screenshot_{timestamp}.png")
        screenshot = ImageGrab.grab()
        screenshot.save(filename)
        print(f"Screenshot saved to {filename}")

# Start listening for mouse clicks
with mouse.Listener(on_click=on_click) as listener:
    print("Listening for mouse clicks... Press Ctrl+C to stop.")
    listener.join()

Opwen VSCode and copy code to VSCode and create a new python codes.

PS C:\Users\hwang\Documents> python C:\Users\hwang\OneDrive\Documents\chatGPTtoPythonApp.py
click mouse and creted screenshots.png files at 
C:\Users\hwang\Documents\screenshots


#########################################
python_book analysis
Read pdf file and analyis text data.

open file C:\Workarea\python_book analysis\Read_pdf.py at VSCodes.
RUnning debug of Read_pdf.py file.

first install pip
then 
C:\Workarea\python_book analysis>pip install pydef --user
C:\Workarea\python_book analysis>pip install pdfplumber --user
C:\Workarea\python_book analysis>pip install transformers --user
C:\Workarea\python_book analysis>pip install pandas --user

Running Read_pdf.py

import pypdf
import pdfplumber
from transformers import pipeline
import pandas as pd

def extract_paragraphs_from_pdf(file_path):
    paragraphs = []
    with pdfplumber.open(file_path) as pdf:
        for page in pdf.pages:
            text = page.extract_text()
            if text:
                for line in text.split('\n'):
                    if line.strip():
                        paragraphs.append(line.strip())
    return paragraphs

def split_long_paragraphs(paragraphs, max_length=300):
    res = []
    for p in paragraphs:
        if len(p) <= max_length:
            res.append(p)
        else:
            buf = ""
            for sent in p.split('。'):
                if len(buf) + len(sent) < max_length:
                    buf += sent + "。"
                else:
                    res.append(buf)
                    buf = sent + "。"
            if buf:
                res.append(buf)
    return res

def classify_paragraphs(paragraphs, labels):
    # Ensure the classifier is initialized
    if 'classifier' not in globals():
        global classifier
        classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli")

    out = []
    for i, p in enumerate(paragraphs):
        res = classifier(p, candidate_labels=labels)
        out.append({"段落编号": i+1, "分类标签": res['labels'][0], "原文内容": p})
        if (i+1)%20 == 0:
            print(f"已分类 {i+1}/{len(paragraphs)} 段...")
    return out

def save_to_excel(data, path):
    pd.DataFrame(data).to_excel(path, index=False)
    print("已保存 Excel：", path)

# Define labels here
labels = ["事实", "议论", "抒情", "逻辑推理", "结论"]


if __name__ == "__main__":
    paras = extract_paragraphs_from_pdf("Bridge Launching (Marco Rosignoli)(readable).pdf")
    print(paras)

    split_paras = split_long_paragraphs(paras)
    print(f"总段落数（拆分后）：{len(split_paras)}")

    # Add the code from cell q3XVaC6A8mvx here
    print("原始段落数量：", len(paras))
    print("拆分后段落数量：", len(split_paras))

    # 只看前 2 段是否正常
    for i, p in enumerate(split_paras[:2]):
        print(f"段落 {i+1}：{p[:60]}...")


    # 只处理前50段以便测试，可根据需要增加
    results = classify_paragraphs(split_paras[:50], labels)

    if results:
        excel_path = "bridge_summary.xlsx"
        save_to_excel(results, excel_path)
    else:
        print("没有生成分类结果，跳过保存Excel和Word报告。")


$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

https://chatgpt.com/c/685afb2f-99ec-800c-8a93-059634a91886

✅ Goal Recap
Fixed-size window: e.g., 400x300.

Each video frame is resized to fit within that window, preserving aspect ratio.

The result is centered inside the window.

If the aspect ratio doesn't match, it will show black bars (letterboxing or pillarboxing).

✅ Python Script: Fit Entire Video Frame Within a Crop Window

import cv2
import glob
import os
import time
import numpy as np

# Folder containing videos
video_folder = "path/to/your/videos"
video_extensions = ('*.mp4', '*.avi', '*.mov', '*.mkv')

# Size of the fixed crop window
target_width = 400
target_height = 300

def get_video_files(folder, extensions):
    video_files = []
    for ext in extensions:
        video_files.extend(glob.glob(os.path.join(folder, ext)))
    return sorted(video_files)

def letterbox_frame(frame, target_w, target_h):
    h, w = frame.shape[:2]
    scale = min(target_w / w, target_h / h)
    new_w, new_h = int(w * scale), int(h * scale)
    
    resized = cv2.resize(frame, (new_w, new_h))
    result = np.zeros((target_h, target_w, 3), dtype=np.uint8)

    x_offset = (target_w - new_w) // 2
    y_offset = (target_h - new_h) // 2

    result[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized
    return result

def play_video_fit_in_window(file_path):
    cap = cv2.VideoCapture(file_path)
    if not cap.isOpened():
        print(f"Failed to open {file_path}")
        return

    print(f"Playing: {file_path}")
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        fitted = letterbox_frame(frame, target_width, target_height)
        cv2.imshow("Fit Video in Crop Area", fitted)

        if cv2.waitKey(25) & 0xFF == ord('q'):
            break

    cap.release()

while True:
    video_files = get_video_files(video_folder, video_extensions)
    if not video_files:
        print("No video files found.")
        break

    for video_file in video_files:
        play_video_fit_in_window(video_file)
        time.sleep(1)

cv2.destroyAllWindows()
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$


